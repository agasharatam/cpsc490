{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.utils.data as data\nimport os\nimport numpy as np\nimport json","metadata":{"id":"XqOapteeQeH7","trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')","metadata":{"id":"HDA0tK6XQh_0","trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"def expandData(weekly_songs, encoded):\n    res = []\n    for pos in range(len(encoded)):\n        item = []\n        for t in range(len(encoded[pos])):\n            code = encoded[pos][t]\n            item.append(weekly_songs[code[0]][code[1]])\n        res.append(item)\n    \n    return res","metadata":{"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"class JsonDataset(data.Dataset):\n    def __init__(self, data_path):\n        f = open(data_path, 'r')\n        d = json.loads(f.read())\n        self.weekly_songs = d['weekly_songs']\n        self.data = d['data']\n        f.close()\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, index):\n        return expandData(self.weekly_songs, self.data[index][0]), \\\n            torch.FloatTensor(self.data[index][1]), \\\n            torch.LongTensor([self.data[index][2]])","metadata":{"id":"4539zd7OS8u9","trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"train_data = JsonDataset('/kaggle/input/cpsc490/combined-train.json')\nvalidation_data = JsonDataset('/kaggle/input/cpsc490/combined-validation.json')\ntest_data = JsonDataset('/kaggle/input/cpsc490/combined-test.json')","metadata":{"id":"tYtBZxmfVefp","trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"x_seq_num = len(train_data[0][0])\nx_seq_size = 10\nrnn_num_layers = 2\n\nx_size = train_data[0][1].shape[0]\nfc_hidden_size = 200\nfc_num_layers = 5\n\nbatch_size = 1","metadata":{"id":"yHrlQ0mMdIzQ","trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"params = {'batch_size': batch_size, 'shuffle': True, 'num_workers': 1, 'pin_memory': True}\ntrain_loader = data.DataLoader(train_data, **params)\nvalidation_loader = data.DataLoader(validation_data, **params)\ntest_loader = data.DataLoader(test_data, **params)","metadata":{"id":"cgF9wQhTdX86","trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"class RNN(nn.Module):\n    def __init__(self, x_seq_size, rnn_num_layers):\n        super(RNN, self).__init__()\n        \n        self.rnn_num_layers = rnn_num_layers\n\n        self.rnn = nn.LSTM(x_seq_size, x_seq_size, rnn_num_layers,\n                          batch_first = True)\n\n    def forward(self, x_seq):\n        h0 = torch.zeros(self.rnn_num_layers, x_seq.shape[0], x_seq.shape[2]).to(device)\n        c0 = torch.zeros(self.rnn_num_layers, x_seq.shape[0], x_seq.shape[2]).to(device)\n        \n        out, _ = self.rnn(x_seq, (h0, c0))\n        return out[:, -1, :]","metadata":{"id":"ruw1C_2edjo5","trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"class Naive(nn.Module):\n    def __init__(self, x_size, fc_hidden_size, fc_num_layers):\n        super(Naive, self).__init__()\n        \n        d = 0.5\n        \n        seq = []\n        seq.append(nn.Linear(x_size, fc_hidden_size))\n        seq.append(nn.Tanh())\n        seq.append(nn.Dropout(d))\n\n        for _ in range(fc_num_layers - 1):\n            seq.append(nn.Linear(fc_hidden_size, fc_hidden_size))\n            seq.append(nn.Tanh())\n            seq.append(nn.Dropout(d))\n        \n        seq.append(nn.Linear(fc_hidden_size, 2))\n        self.fc = nn.Sequential(*seq)\n        \n    def forward(self, x):\n        out = self.fc(x)\n        return out","metadata":{"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"class Combined(nn.Module):\n    def __init__(self, x_seq_size, rnn_num_layers, x_size, fc_hidden_size, fc_num_layers):\n        super(Combined, self).__init__()\n        \n        self.rnn = RNN(x_seq_size, rnn_num_layers)\n        self.rnn.load_state_dict(torch.load('/kaggle/input/cpsc490/best_rnn_2.pth'))\n        \n        self.naive = Naive(x_seq_num, fc_hidden_size, fc_num_layers)\n        self.naive.load_state_dict(torch.load('/kaggle/input/cpsc490/best_naive_9.pth'))\n        \n    def forward(self, x_seq, x):\n        next_input = None\n        \n        layer = None\n        for s in x_seq:\n            if s == []:\n                res = torch.FloatTensor([0]).to(device)\n                res = torch.reshape(res, (1, 1))\n            else:     \n                s = torch.FloatTensor(s).to(device)\n                s = torch.reshape(s, (1, s.shape[0], s.shape[1]))\n                res = self.rnn(s)\n                res = torch.exp(-25 * torch.square(torch.norm(res - x, 2)))\n                res = torch.reshape(res, (1, 1))\n            \n            if layer is None:\n                layer = res\n            else:\n                layer = torch.cat((layer, res), dim=1)\n            \n        layer = torch.reshape(layer, (1, -1))\n        if next_input is None:\n            next_input = layer\n        else:\n            next_input = torch.cat((next_input, layer), dim=0)\n            \n        out = self.naive(next_input)\n        return out","metadata":{"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"model = Combined(x_seq_size, rnn_num_layers, x_size, fc_hidden_size, fc_num_layers).to(device)","metadata":{"id":"6P1JJvbqMO5q","outputId":"12f1a8da-08c8-4eff-c1c7-69e3af3b7d5e","trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"# Test\nd = train_data + validation_data + test_data\n\nmodel.eval()\nwith torch.no_grad():\n    n_correct = 0\n    total = 0\n        \n    for i in range(len(d)):\n        x_seq, x, targets = d[i]\n        x = x.to(device)\n        targets = torch.flatten(targets).to(device)\n\n        outputs = model(x_seq, x)\n        _, predicted = torch.max(outputs.data, 1)\n\n        total += 1\n        n_correct += (predicted == targets).sum().item()\n    \n    acc = float(100 * n_correct / total)\n    print('Test accuracy: {}%'.format(acc))","metadata":{"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"Test accuracy: 66.0%\n","output_type":"stream"}]}]}