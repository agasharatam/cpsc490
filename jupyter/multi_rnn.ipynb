{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "multi-rnn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqOapteeQeH7"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data\n",
        "import os\n",
        "import numpy as np\n",
        "import json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDA0tK6XQh_0"
      },
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBGXPIaUqKwW"
      },
      "source": [
        "def expandData(weekly_songs, encoded):\n",
        "    res = []\n",
        "    for pos in range(len(encoded)):\n",
        "        item = []\n",
        "        for t in range(len(encoded[0])):\n",
        "            code = encoded[pos][t]\n",
        "            item.append(weekly_songs[code[0]][code[1]])\n",
        "        res.append(item)\n",
        "\n",
        "    available = [i for i in range(len(res))]\n",
        "    res2 = []\n",
        "    while len(available) > 0:\n",
        "        idx = available[np.random.randint(len(available))]\n",
        "        res2.append(res[idx])\n",
        "        available.remove(idx)\n",
        "    \n",
        "    return res2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4539zd7OS8u9"
      },
      "source": [
        "class JsonDataset(data.Dataset):\n",
        "    \"\"\"\n",
        "    Each item is a tuple t, with:\n",
        "    t[0].shape = num_top_songs X sequence_length X x_seq_size\n",
        "    t[1].shape = x_size\n",
        "    t[2].shape = 1\n",
        "    \"\"\"\n",
        "    def __init__(self, data_path):\n",
        "        f = open(data_path, 'r')\n",
        "        d = json.loads(f.read())\n",
        "        self.weekly_songs = d['weekly_songs']\n",
        "        self.data = d['data']\n",
        "        f.close()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return torch.FloatTensor(expandData(self.weekly_songs, self.data[index][0])), \\\n",
        "            torch.FloatTensor(self.data[index][1]), \\\n",
        "            torch.LongTensor([float(self.data[index][2])])\n",
        "        #tmp = expandData(self.weekly_songs, self.data[index][0])\n",
        "        #if tmp[-1][-1][-1] > 0.5:\n",
        "        #    return torch.FloatTensor(tmp), torch.FloatTensor(self.data[index][1]), torch.LongTensor([1])\n",
        "        #else:\n",
        "        #    return torch.FloatTensor(tmp), torch.FloatTensor(self.data[index][1]), torch.LongTensor([0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYtBZxmfVefp"
      },
      "source": [
        "train_data = JsonDataset('drive/MyDrive/cpsc490/small-multi-rnn-train.json')\n",
        "validation_data = JsonDataset('drive/MyDrive/cpsc490/small-multi-rnn-validation.json')\n",
        "test_data = JsonDataset('drive/MyDrive/cpsc490/small-multi-rnn-test.json')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4_OY4e5BCAt",
        "outputId": "80c155f6-12a3-4347-d551-5113af2a70a2"
      },
      "source": [
        "\"\"\"\n",
        "item = train_data[0][0]\n",
        "\n",
        "sum = 0\n",
        "for i in range(0, 199):\n",
        "    sum += np.linalg.norm(item[1][i] - item[1][i + 1])\n",
        "\n",
        "print(sum)\n",
        "\n",
        "point = item[np.random.randint(63)][i]\n",
        "sum2 = 0\n",
        "for i in range(0, 199):\n",
        "    point2 = item[np.random.randint(63)][i + 1]\n",
        "    sum2 += np.linalg.norm(point - point2)\n",
        "    point = point2\n",
        "\n",
        "print(sum2)\n",
        "\"\"\"\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "27.238822096958756\n",
            "341.9393405262381\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHrlQ0mMdIzQ"
      },
      "source": [
        "num_top_songs = train_data[0][0].shape[0]\n",
        "\n",
        "x_seq_size = train_data[0][0].shape[2]\n",
        "rnn_hidden_size = 30\n",
        "rnn_num_layers = 2\n",
        "\n",
        "x_size = train_data[0][1].shape[0]\n",
        "fc_hidden_size = 3000\n",
        "fc_num_layers = 10\n",
        "\n",
        "batch_size = 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgF9wQhTdX86"
      },
      "source": [
        "params = {'batch_size': 64, 'shuffle': True, 'num_workers': 1, 'pin_memory': True}\n",
        "train_loader = data.DataLoader(train_data, **params)\n",
        "validation_loader = data.DataLoader(validation_data, **params)\n",
        "test_loader = data.DataLoader(test_data, **params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruw1C_2edjo5"
      },
      "source": [
        "class MultiRNN(nn.Module):\n",
        "    def __init__(self, num_top_songs, x_seq_size, rnn_hidden_size, rnn_num_layers, x_size, fc_hidden_size, fc_num_layers):\n",
        "        super(MultiRNN, self).__init__()\n",
        "\n",
        "        self.num_top_songs = num_top_songs\n",
        "        self.rnn_hidden_size = rnn_hidden_size\n",
        "        self.rnn_num_layers = rnn_num_layers\n",
        "\n",
        "        self.rnns = nn.ModuleList([nn.LSTM(x_seq_size, rnn_hidden_size, rnn_num_layers,\n",
        "                                            batch_first = True) for _ in range(num_top_songs)])\n",
        "\n",
        "        seq = []\n",
        "        seq.append(nn.Linear(num_top_songs * rnn_hidden_size + x_size, fc_hidden_size))\n",
        "        seq.append(nn.Tanh())\n",
        "        seq.append(nn.Dropout(0.8))\n",
        "\n",
        "        for _ in range(fc_num_layers - 1):\n",
        "            seq.append(nn.Linear(fc_hidden_size, fc_hidden_size))\n",
        "            seq.append(nn.Tanh())\n",
        "            seq.append(nn.Dropout(0.8))\n",
        "        \n",
        "        seq.append(nn.Linear(fc_hidden_size, 2))\n",
        "\n",
        "        self.fc = nn.Sequential(*seq)\n",
        "\n",
        "    def forward(self, x_seqs, x):\n",
        "        hs = None\n",
        "        for i in range(self.num_top_songs):\n",
        "            h0 = torch.zeros(self.rnn_num_layers, x_seqs.shape[0], self.rnn_hidden_size).to(device)\n",
        "            c0 = torch.zeros(self.rnn_num_layers, x_seqs.shape[0], self.rnn_hidden_size).to(device)\n",
        "\n",
        "            out, _ = self.rnns[i](x_seqs[:, i, :, :], (h0, c0))\n",
        "\n",
        "            h = out[:, -1, :] # h.shape = batch_size x rnn_hidden_size\n",
        "            if hs == None:\n",
        "                hs = h\n",
        "            else:\n",
        "                hs = torch.cat((hs, h), 1)\n",
        "\n",
        "        joined = torch.cat((hs, x), 1) # joined.shape = batch_size x (num_top_songs * rnn_hidden_size + x_size)\n",
        "        out = self.fc(joined)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_Wqe7PcMMAi"
      },
      "source": [
        "def train(model, criterion, optimizer):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for i, (x_seqs, x, targets) in enumerate(train_loader):\n",
        "        x_seqs = x_seqs.to(device)\n",
        "        x = x.to(device)\n",
        "        targets = torch.flatten(targets).to(device)\n",
        "\n",
        "        outputs = model(x_seqs, x)\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total += targets.size(0)\n",
        "        train_loss += loss.item() * targets.size(0)\n",
        "        _, predicted = outputs.max(1)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "        \n",
        "    epoch_train_loss = train_loss / total\n",
        "    epoch_train_acc = float(100 * correct / total)\n",
        "\n",
        "    return epoch_train_loss, epoch_train_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxB81t-kMNcl"
      },
      "source": [
        "def validation(model, criterion):\n",
        "    model.eval()\n",
        "    validation_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (x_seqs, x, targets) in enumerate(validation_loader):\n",
        "            x_seqs = x_seqs.to(device)\n",
        "            x = x.to(device)\n",
        "            targets = torch.flatten(targets).to(device)\n",
        "\n",
        "            outputs = model(x_seqs, x)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "        total += targets.size(0)\n",
        "        validation_loss += loss.item() * targets.size(0)\n",
        "        _, predicted = outputs.max(1)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "        \n",
        "    epoch_validation_loss = validation_loss / total\n",
        "    epoch_validation_acc = float(100 * correct / total)\n",
        "\n",
        "    return epoch_validation_loss, epoch_validation_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6P1JJvbqMO5q",
        "outputId": "12f1a8da-08c8-4eff-c1c7-69e3af3b7d5e"
      },
      "source": [
        "weight_zero = len([i for i in range(len(train_data)) if train_data[i][2] == 1]) / len(train_data)\n",
        "print('weight_zero: {}'.format(weight_zero))\n",
        "\n",
        "model = MultiRNN(num_top_songs, x_seq_size, rnn_hidden_size, rnn_num_layers, x_size, fc_hidden_size, fc_num_layers).to(device)\n",
        "criterion = nn.CrossEntropyLoss(weight=torch.tensor([weight_zero, 1 - weight_zero]).to(device))\n",
        "#criterion = nn.CrossEntropyLoss().to(device)\n",
        "#criterion = nn.MSELoss().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)  \n",
        "\n",
        "num_epochs = 100"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weight_zero: 0.4828125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXp6xbzzMRe_"
      },
      "source": [
        "# Train\n",
        "best_validation_loss = None\n",
        "\n",
        "for epoch in range(0, num_epochs):\n",
        "    epoch_train_loss, epoch_train_acc = train(model, criterion, optimizer)\n",
        "    epoch_validation_loss, epoch_validation_acc = validation(\n",
        "                                                    model, criterion)\n",
        "    \n",
        "    if best_validation_loss == None or epoch_validation_loss < best_validation_loss:\n",
        "        torch.save(model.state_dict(), 'best_multi_rnn.pth')\n",
        "        print('Saved.')\n",
        "        best_validation_loss = epoch_validation_loss\n",
        "\n",
        "    print('Epoch {}. Training loss: {} ({}% accuracy). Validation loss: {} ({}% accuracy)'\n",
        "        .format(epoch + 1, \n",
        "                format(epoch_train_loss, '.4f'), format(epoch_train_acc, '.4f'),\n",
        "                format(epoch_validation_loss, '.4f'), format(epoch_validation_acc, '.4f')))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_aGVAX0tgXK",
        "outputId": "b55bb14a-1e76-4af3-9cc2-4884088abb70"
      },
      "source": [
        "# Test\n",
        "model.load_state_dict(torch.load('best_multi_rnn.pth'))\n",
        "\n",
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    for i, (x_seq, x, targets) in enumerate(test_loader):\n",
        "        x_seq = x_seq.to(device)\n",
        "        x = x.to(device)\n",
        "        targets = torch.flatten(targets).to(device)\n",
        "        #targets = targets.reshape(-1, 1).to(device)\n",
        "\n",
        "        outputs = model(x_seq, x)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        \n",
        "        #if i == 0:\n",
        "            #print(outputs)\n",
        "            #print(predicted)\n",
        "            #print(targets)\n",
        "\n",
        "        n_samples += x_seq.shape[0]\n",
        "        n_correct += (predicted == targets).sum().item()\n",
        "    \n",
        "    acc = float(100 * n_correct / n_samples)\n",
        "    print('Test accuracy: {}%'.format(acc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 45.0%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}