{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.utils.data as data\nimport os\nimport numpy as np\nimport json","metadata":{"id":"XqOapteeQeH7","trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')","metadata":{"id":"HDA0tK6XQh_0","trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"def expandData(weekly_songs, encoded):\n    res = []\n    for pos in range(len(encoded)):\n        item = []\n        for t in range(len(encoded[0])):\n            code = encoded[pos][t]\n            item.append(weekly_songs[code[0]][code[1]])\n        res.append(item)\n\n    available = [i for i in range(len(res))]\n    res2 = []\n    while len(available) > 0:\n        idx = available[np.random.randint(len(available))]\n        res2.append(res[idx])\n        available.remove(idx)\n    \n    return res2","metadata":{"id":"OBGXPIaUqKwW","trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class JsonDataset(data.Dataset):\n    \"\"\"\n    Each item is a tuple t, with:\n    t[0].shape = num_top_songs X sequence_length X x_seq_size\n    t[1].shape = x_size\n    t[2].shape = 1\n    \"\"\"\n    def __init__(self, data_path):\n        f = open(data_path, 'r')\n        d = json.loads(f.read())\n        self.weekly_songs = d['weekly_songs']\n        self.data = d['data']\n        f.close()\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, index):\n        return torch.FloatTensor(expandData(self.weekly_songs, self.data[index][0])), \\\n            torch.FloatTensor(self.data[index][1]), \\\n            torch.LongTensor([float(self.data[index][2])])\n        #tmp = expandData(self.weekly_songs, self.data[index][0])\n        #if tmp[-1][-1][-1] > 0.5:\n        #    return torch.FloatTensor(tmp), torch.FloatTensor(self.data[index][1]), torch.LongTensor([1])\n        #else:\n        #    return torch.FloatTensor(tmp), torch.FloatTensor(self.data[index][1]), torch.LongTensor([0])","metadata":{"id":"4539zd7OS8u9","trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_data = JsonDataset('/kaggle/input/cpsc490/small-multi-rnn-train.json')\nvalidation_data = JsonDataset('/kaggle/input/cpsc490/small-multi-rnn-validation.json')\ntest_data = JsonDataset('/kaggle/input/cpsc490/small-multi-rnn-test.json')","metadata":{"id":"tYtBZxmfVefp","trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nitem = train_data[0][0]\n\nsum = 0\nfor i in range(0, 199):\n    sum += np.linalg.norm(item[1][i] - item[1][i + 1])\n\nprint(sum)\n\npoint = item[np.random.randint(63)][i]\nsum2 = 0\nfor i in range(0, 199):\n    point2 = item[np.random.randint(63)][i + 1]\n    sum2 += np.linalg.norm(point - point2)\n    point = point2\n\nprint(sum2)\n\"\"\"\n","metadata":{"id":"M4_OY4e5BCAt","outputId":"80c155f6-12a3-4347-d551-5113af2a70a2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_top_songs = train_data[0][0].shape[0]\n\nx_seq_size = train_data[0][0].shape[2]\nrnn_hidden_size = 30\nrnn_num_layers = 2\n\nx_size = train_data[0][1].shape[0]\nfc_hidden_size = 3000\nfc_num_layers = 1\n\nbatch_size = 64","metadata":{"id":"yHrlQ0mMdIzQ","trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"params = {'batch_size': 64, 'shuffle': True, 'num_workers': 1, 'pin_memory': True}\ntrain_loader = data.DataLoader(train_data, **params)\nvalidation_loader = data.DataLoader(validation_data, **params)\ntest_loader = data.DataLoader(test_data, **params)","metadata":{"id":"cgF9wQhTdX86","trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"class MultiRNN(nn.Module):\n    def __init__(self, num_top_songs, x_seq_size, rnn_hidden_size, rnn_num_layers, x_size, fc_hidden_size, fc_num_layers):\n        super(MultiRNN, self).__init__()\n\n        self.num_top_songs = num_top_songs\n        self.rnn_hidden_size = rnn_hidden_size\n        self.rnn_num_layers = rnn_num_layers\n\n        self.rnns = nn.ModuleList([nn.LSTM(x_seq_size, rnn_hidden_size, rnn_num_layers,\n                                            batch_first = True) for _ in range(num_top_songs)])\n\n        seq = []\n        seq.append(nn.Linear(num_top_songs * rnn_hidden_size + x_size, fc_hidden_size))\n        seq.append(nn.Tanh())\n        #seq.append(nn.Dropout(0.8))\n\n        for _ in range(fc_num_layers - 1):\n            seq.append(nn.Linear(fc_hidden_size, fc_hidden_size))\n            seq.append(nn.Tanh())\n            #seq.append(nn.Dropout(0.8))\n        \n        seq.append(nn.Linear(fc_hidden_size, 2))\n\n        self.fc = nn.Sequential(*seq)\n\n    def forward(self, x_seqs, x):\n        hs = None\n        for i in range(self.num_top_songs):\n            h0 = torch.zeros(self.rnn_num_layers, x_seqs.shape[0], self.rnn_hidden_size).to(device)\n            c0 = torch.zeros(self.rnn_num_layers, x_seqs.shape[0], self.rnn_hidden_size).to(device)\n\n            out, _ = self.rnns[i](x_seqs[:, i, :, :], (h0, c0))\n\n            h = out[:, -1, :] # h.shape = batch_size x rnn_hidden_size\n            if hs == None:\n                hs = h\n            else:\n                hs = torch.cat((hs, h), 1)\n\n        joined = torch.cat((hs, x), 1) # joined.shape = batch_size x (num_top_songs * rnn_hidden_size + x_size)\n        out = self.fc(joined)\n        return out","metadata":{"id":"ruw1C_2edjo5","trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"def train(model, criterion, optimizer):\n    model.train()\n    train_loss = 0\n    correct = 0\n    total = 0\n\n    for i, (x_seqs, x, targets) in enumerate(train_loader):\n        x_seqs = x_seqs.to(device)\n        x = x.to(device)\n        targets = torch.flatten(targets).to(device)\n\n        outputs = model(x_seqs, x)\n        loss = criterion(outputs, targets)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        total += targets.size(0)\n        train_loss += loss.item() * targets.size(0)\n        _, predicted = outputs.max(1)\n        correct += predicted.eq(targets).sum().item()\n        \n    epoch_train_loss = train_loss / total\n    epoch_train_acc = float(100 * correct / total)\n\n    return epoch_train_loss, epoch_train_acc","metadata":{"id":"8_Wqe7PcMMAi","trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def validation(model, criterion):\n    model.eval()\n    validation_loss = 0\n    correct = 0\n    total = 0\n\n    with torch.no_grad():\n        for i, (x_seqs, x, targets) in enumerate(validation_loader):\n            x_seqs = x_seqs.to(device)\n            x = x.to(device)\n            targets = torch.flatten(targets).to(device)\n\n            outputs = model(x_seqs, x)\n            loss = criterion(outputs, targets)\n\n        total += targets.size(0)\n        validation_loss += loss.item() * targets.size(0)\n        _, predicted = outputs.max(1)\n        correct += predicted.eq(targets).sum().item()\n        \n    epoch_validation_loss = validation_loss / total\n    epoch_validation_acc = float(100 * correct / total)\n\n    return epoch_validation_loss, epoch_validation_acc","metadata":{"id":"gxB81t-kMNcl","trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"weight_zero = len([i for i in range(len(train_data)) if train_data[i][2] == 1]) / len(train_data)\nprint('weight_zero: {}'.format(weight_zero))\n\nmodel = MultiRNN(num_top_songs, x_seq_size, rnn_hidden_size, rnn_num_layers, x_size, fc_hidden_size, fc_num_layers).to(device)\ncriterion = nn.CrossEntropyLoss(weight=torch.tensor([weight_zero, 1 - weight_zero]).to(device))\n#criterion = nn.CrossEntropyLoss().to(device)\n#criterion = nn.MSELoss().to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)  \n\nnum_epochs = 100","metadata":{"id":"6P1JJvbqMO5q","outputId":"12f1a8da-08c8-4eff-c1c7-69e3af3b7d5e","trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"weight_zero: 0.4828125\n","output_type":"stream"}]},{"cell_type":"code","source":"# Train\nbest_validation_loss = None\n\nfor epoch in range(0, num_epochs):\n    epoch_train_loss, epoch_train_acc = train(model, criterion, optimizer)\n    epoch_validation_loss, epoch_validation_acc = validation(\n                                                    model, criterion)\n    \n    if best_validation_loss == None or epoch_validation_loss < best_validation_loss:\n        torch.save(model.state_dict(), 'best_multi_rnn.pth')\n        print('Saved.')\n        best_validation_loss = epoch_validation_loss\n\n    print('Epoch {}. Training loss: {} ({}% accuracy). Validation loss: {} ({}% accuracy)'\n        .format(epoch + 1, \n                format(epoch_train_loss, '.4f'), format(epoch_train_acc, '.4f'),\n                format(epoch_validation_loss, '.4f'), format(epoch_validation_acc, '.4f')))\n    ","metadata":{"id":"dXp6xbzzMRe_","trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Saved.\nEpoch 1. Training loss: 0.8686 (51.8750% accuracy). Validation loss: 0.6968 (50.0000% accuracy)\nEpoch 2. Training loss: 0.7110 (53.7500% accuracy). Validation loss: 0.7068 (46.8750% accuracy)\nSaved.\nEpoch 3. Training loss: 0.6958 (48.2812% accuracy). Validation loss: 0.6954 (43.7500% accuracy)\nSaved.\nEpoch 4. Training loss: 0.6971 (51.7188% accuracy). Validation loss: 0.6933 (56.2500% accuracy)\nEpoch 5. Training loss: 0.6947 (47.9688% accuracy). Validation loss: 0.7189 (34.3750% accuracy)\nSaved.\nEpoch 6. Training loss: 0.6906 (51.0938% accuracy). Validation loss: 0.6904 (62.5000% accuracy)\nEpoch 7. Training loss: 0.6933 (52.9688% accuracy). Validation loss: 0.6932 (53.1250% accuracy)\nEpoch 8. Training loss: 0.6905 (51.5625% accuracy). Validation loss: 0.7015 (43.7500% accuracy)\nEpoch 9. Training loss: 0.6909 (49.6875% accuracy). Validation loss: 0.7033 (37.5000% accuracy)\nEpoch 10. Training loss: 0.6906 (55.3125% accuracy). Validation loss: 0.6940 (46.8750% accuracy)\nEpoch 11. Training loss: 0.6882 (54.6875% accuracy). Validation loss: 0.6951 (46.8750% accuracy)\nEpoch 12. Training loss: 0.6882 (53.9062% accuracy). Validation loss: 0.6959 (50.0000% accuracy)\nEpoch 13. Training loss: 0.6926 (51.8750% accuracy). Validation loss: 0.7415 (37.5000% accuracy)\nSaved.\nEpoch 14. Training loss: 0.6967 (51.2500% accuracy). Validation loss: 0.6901 (56.2500% accuracy)\nEpoch 15. Training loss: 0.6890 (52.8125% accuracy). Validation loss: 0.7043 (43.7500% accuracy)\nEpoch 16. Training loss: 0.6874 (56.2500% accuracy). Validation loss: 0.7228 (43.7500% accuracy)\nEpoch 17. Training loss: 0.6871 (55.7812% accuracy). Validation loss: 0.7228 (46.8750% accuracy)\nSaved.\nEpoch 18. Training loss: 0.6881 (55.0000% accuracy). Validation loss: 0.6725 (65.6250% accuracy)\nEpoch 19. Training loss: 0.6863 (55.9375% accuracy). Validation loss: 0.7170 (40.6250% accuracy)\nEpoch 20. Training loss: 0.6867 (55.4688% accuracy). Validation loss: 0.7312 (40.6250% accuracy)\nEpoch 21. Training loss: 0.6851 (55.6250% accuracy). Validation loss: 0.7236 (46.8750% accuracy)\nEpoch 22. Training loss: 0.6889 (56.2500% accuracy). Validation loss: 0.7576 (34.3750% accuracy)\nEpoch 23. Training loss: 0.6985 (48.4375% accuracy). Validation loss: 0.6956 (59.3750% accuracy)\nEpoch 24. Training loss: 0.6906 (51.8750% accuracy). Validation loss: 0.7114 (40.6250% accuracy)\nEpoch 25. Training loss: 0.6938 (54.5312% accuracy). Validation loss: 0.7151 (34.3750% accuracy)\nEpoch 26. Training loss: 0.6865 (55.7812% accuracy). Validation loss: 0.6956 (62.5000% accuracy)\nEpoch 27. Training loss: 0.6883 (55.9375% accuracy). Validation loss: 0.7004 (59.3750% accuracy)\nEpoch 28. Training loss: 0.6852 (57.6562% accuracy). Validation loss: 0.6772 (50.0000% accuracy)\nEpoch 29. Training loss: 0.6841 (54.5312% accuracy). Validation loss: 0.7198 (50.0000% accuracy)\nEpoch 30. Training loss: 0.6847 (53.9062% accuracy). Validation loss: 0.7196 (40.6250% accuracy)\nSaved.\nEpoch 31. Training loss: 0.6838 (55.7812% accuracy). Validation loss: 0.6610 (56.2500% accuracy)\nEpoch 32. Training loss: 0.6820 (56.0938% accuracy). Validation loss: 0.6844 (59.3750% accuracy)\nEpoch 33. Training loss: 0.6854 (56.2500% accuracy). Validation loss: 0.7005 (53.1250% accuracy)\nEpoch 34. Training loss: 0.6829 (57.3438% accuracy). Validation loss: 0.7148 (43.7500% accuracy)\nEpoch 35. Training loss: 0.6835 (57.0312% accuracy). Validation loss: 0.7351 (37.5000% accuracy)\nEpoch 36. Training loss: 0.6809 (56.7188% accuracy). Validation loss: 0.7185 (43.7500% accuracy)\nEpoch 37. Training loss: 0.6870 (54.5312% accuracy). Validation loss: 0.7263 (31.2500% accuracy)\nEpoch 38. Training loss: 0.6909 (54.3750% accuracy). Validation loss: 0.7081 (46.8750% accuracy)\nEpoch 39. Training loss: 0.6832 (57.8125% accuracy). Validation loss: 0.7024 (43.7500% accuracy)\nEpoch 40. Training loss: 0.6812 (56.4062% accuracy). Validation loss: 0.7864 (40.6250% accuracy)\nEpoch 41. Training loss: 0.6892 (52.9688% accuracy). Validation loss: 0.7930 (31.2500% accuracy)\nEpoch 42. Training loss: 0.6882 (53.4375% accuracy). Validation loss: 0.6833 (62.5000% accuracy)\nEpoch 43. Training loss: 0.6880 (52.6562% accuracy). Validation loss: 0.7074 (46.8750% accuracy)\nEpoch 44. Training loss: 0.6838 (56.4062% accuracy). Validation loss: 0.7127 (56.2500% accuracy)\nEpoch 45. Training loss: 0.6856 (55.4688% accuracy). Validation loss: 0.7445 (46.8750% accuracy)\nEpoch 46. Training loss: 0.6807 (56.8750% accuracy). Validation loss: 0.7116 (53.1250% accuracy)\nEpoch 47. Training loss: 0.6839 (56.4062% accuracy). Validation loss: 0.7097 (50.0000% accuracy)\nEpoch 48. Training loss: 0.6907 (55.0000% accuracy). Validation loss: 0.7090 (50.0000% accuracy)\nEpoch 49. Training loss: 0.6813 (56.8750% accuracy). Validation loss: 0.7163 (46.8750% accuracy)\nEpoch 50. Training loss: 0.6840 (56.5625% accuracy). Validation loss: 0.7149 (50.0000% accuracy)\nEpoch 51. Training loss: 0.6930 (53.7500% accuracy). Validation loss: 0.7250 (50.0000% accuracy)\nEpoch 52. Training loss: 0.6901 (50.1562% accuracy). Validation loss: 0.6997 (34.3750% accuracy)\nEpoch 53. Training loss: 0.6846 (55.1562% accuracy). Validation loss: 0.7176 (50.0000% accuracy)\nEpoch 54. Training loss: 0.6738 (58.4375% accuracy). Validation loss: 0.7863 (56.2500% accuracy)\nEpoch 55. Training loss: 0.6960 (54.8438% accuracy). Validation loss: 0.7397 (40.6250% accuracy)\nEpoch 56. Training loss: 0.6819 (57.0312% accuracy). Validation loss: 0.7315 (46.8750% accuracy)\nEpoch 57. Training loss: 0.6835 (55.9375% accuracy). Validation loss: 0.6973 (50.0000% accuracy)\nEpoch 58. Training loss: 0.6846 (55.3125% accuracy). Validation loss: 0.7593 (28.1250% accuracy)\nEpoch 59. Training loss: 0.6768 (57.5000% accuracy). Validation loss: 0.7545 (53.1250% accuracy)\nEpoch 60. Training loss: 0.6923 (55.9375% accuracy). Validation loss: 0.6794 (59.3750% accuracy)\nEpoch 61. Training loss: 0.6906 (52.5000% accuracy). Validation loss: 0.7273 (28.1250% accuracy)\nEpoch 62. Training loss: 0.6880 (52.6562% accuracy). Validation loss: 0.7582 (43.7500% accuracy)\nEpoch 63. Training loss: 0.6800 (54.8438% accuracy). Validation loss: 0.7567 (43.7500% accuracy)\nEpoch 64. Training loss: 0.6858 (57.1875% accuracy). Validation loss: 0.7540 (59.3750% accuracy)\nEpoch 65. Training loss: 0.6850 (54.8438% accuracy). Validation loss: 0.6786 (50.0000% accuracy)\nEpoch 66. Training loss: 0.6822 (54.5312% accuracy). Validation loss: 0.7073 (53.1250% accuracy)\nEpoch 67. Training loss: 0.6753 (58.1250% accuracy). Validation loss: 0.7539 (37.5000% accuracy)\nEpoch 68. Training loss: 0.6819 (55.9375% accuracy). Validation loss: 0.7327 (56.2500% accuracy)\nEpoch 69. Training loss: 0.6787 (57.8125% accuracy). Validation loss: 0.7246 (50.0000% accuracy)\nEpoch 70. Training loss: 0.6844 (54.0625% accuracy). Validation loss: 0.7254 (46.8750% accuracy)\nEpoch 71. Training loss: 0.6825 (55.7812% accuracy). Validation loss: 0.7217 (40.6250% accuracy)\nEpoch 72. Training loss: 0.6824 (56.0938% accuracy). Validation loss: 0.6990 (53.1250% accuracy)\nEpoch 73. Training loss: 0.6835 (56.0938% accuracy). Validation loss: 0.7769 (46.8750% accuracy)\nEpoch 74. Training loss: 0.6816 (54.8438% accuracy). Validation loss: 0.6833 (56.2500% accuracy)\nEpoch 75. Training loss: 0.6817 (57.8125% accuracy). Validation loss: 0.7215 (50.0000% accuracy)\nEpoch 76. Training loss: 0.6847 (55.9375% accuracy). Validation loss: 0.6933 (53.1250% accuracy)\nEpoch 77. Training loss: 0.6828 (54.8438% accuracy). Validation loss: 0.7357 (46.8750% accuracy)\nEpoch 78. Training loss: 0.6820 (58.4375% accuracy). Validation loss: 0.6928 (50.0000% accuracy)\nEpoch 79. Training loss: 0.6822 (56.7188% accuracy). Validation loss: 0.7094 (53.1250% accuracy)\nEpoch 80. Training loss: 0.6766 (56.8750% accuracy). Validation loss: 0.7521 (40.6250% accuracy)\nEpoch 81. Training loss: 0.6778 (58.4375% accuracy). Validation loss: 0.7863 (31.2500% accuracy)\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-bba04d0f6a65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mepoch_train_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_train_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     epoch_validation_loss, epoch_validation_acc = validation(\n\u001b[1;32m      7\u001b[0m                                                     model, criterion)\n","\u001b[0;32m<ipython-input-11-9aa407188b88>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, criterion, optimizer)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"# Test\nmodel.load_state_dict(torch.load('best_multi_rnn.pth'))\n\nwith torch.no_grad():\n    n_correct = 0\n    n_samples = 0\n    for i, (x_seq, x, targets) in enumerate(test_loader):\n        x_seq = x_seq.to(device)\n        x = x.to(device)\n        targets = torch.flatten(targets).to(device)\n        #targets = targets.reshape(-1, 1).to(device)\n\n        outputs = model(x_seq, x)\n        _, predicted = torch.max(outputs.data, 1)\n        \n        #if i == 0:\n            #print(outputs)\n            #print(predicted)\n            #print(targets)\n\n        n_samples += x_seq.shape[0]\n        n_correct += (predicted == targets).sum().item()\n    \n    acc = float(100 * n_correct / n_samples)\n    print('Test accuracy: {}%'.format(acc))","metadata":{"id":"N_aGVAX0tgXK","outputId":"b55bb14a-1e76-4af3-9cc2-4884088abb70"},"execution_count":null,"outputs":[]}]}